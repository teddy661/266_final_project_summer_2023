{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"INFO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the appropriate datasets and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131911, 2)\n"
     ]
    }
   ],
   "source": [
    "import models.data_load as data_load\n",
    "\n",
    "(\n",
    "    train_input_ids,\n",
    "    train_token_type_ids,\n",
    "    train_mask,\n",
    "    train_impossible,\n",
    "    train_start_positions,\n",
    "    train_end_positions,\n",
    "    qas_id,\n",
    ") = data_load.load_train()\n",
    "\n",
    "train_labels = np.vstack([train_start_positions, train_end_positions]).T\n",
    "print(train_labels.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned and average pooling alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"learned_pooler\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 386, 1024,   0           []                               \n",
      "                                25)]                                                              \n",
      "                                                                                                  \n",
      " learned_pooler (LearnedPooler)  (None, 386, 1024)   26          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 386, 2)       2050        ['learned_pooler[0][0]']         \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(None, 386, 1),     0           ['dense[0][0]']                  \n",
      "                                 (None, 386, 1)]                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 386)         0           ['tf.split[0][0]']               \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TFOpLa  (None, 386)         0           ['tf.split[0][1]']               \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,076\n",
      "Trainable params: 2,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from layers.learned_pooler import get_learned_pooling_model\n",
    "\n",
    "learned_pooling_model = get_learned_pooling_model()\n",
    "learned_pooling_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"average_pooler\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 386, 1024,   0           []                               \n",
      "                                25)]                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 386, 1024)   0           ['input_2[0][0]']                \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 386, 2)       2050        ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)        [(None, 386, 1),     0           ['dense_1[0][0]']                \n",
      "                                 (None, 386, 1)]                                                  \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_2 (TFOpLa  (None, 386)         0           ['tf.split_1[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_3 (TFOpLa  (None, 386)         0           ['tf.split_1[0][1]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,050\n",
      "Trainable params: 2,050\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from layers.average_pooler import get_average_pooler\n",
    "\n",
    "average_pooler_model = get_average_pooler()\n",
    "average_pooler_model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f29bb7eee50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start generator with training labels, pointing to data directory with embeddings\n",
    "\n",
    "\n",
    "import models.bert_large_uncased as bert_large_uncased\n",
    "\n",
    "bert_model = bert_large_uncased.create_bert_qa_model(optimizer=\"adam\")\n",
    "bert_model.load_weights(\"./results/bert-large-uncased/training_checkpoints/ckpt_0004.ckpt\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models are compiled as a bi-headed model, the first representing span start position and the second representing span end position. No activation is applied as the heads come directly from splitting a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # monitor accuracy during the training process\n",
    "    model.compile(loss=[loss, loss], optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Gather a list of models to fit\n",
    "# Since fitting is typically faster than data load, it is beneficial to many models at once\n",
    "model_list = [average_pooler_model, learned_pooling_model]\n",
    "\n",
    "for model_current in model_list:\n",
    "    compile_model(model_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10.5645 - tf.compat.v1.squeeze_2_loss: 5.0498 - tf.compat.v1.squeeze_3_loss: 5.5147 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.3220 - tf.compat.v1.squeeze_loss: 5.8968 - tf.compat.v1.squeeze_1_loss: 5.4251 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 11.3841 - tf.compat.v1.squeeze_2_loss: 5.6277 - tf.compat.v1.squeeze_3_loss: 5.7564 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10.1114 - tf.compat.v1.squeeze_loss: 5.4775 - tf.compat.v1.squeeze_1_loss: 4.6340 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10.4119 - tf.compat.v1.squeeze_2_loss: 5.2343 - tf.compat.v1.squeeze_3_loss: 5.1776 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 11.0114 - tf.compat.v1.squeeze_loss: 5.8751 - tf.compat.v1.squeeze_1_loss: 5.1363 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 12.0512 - tf.compat.v1.squeeze_2_loss: 6.0713 - tf.compat.v1.squeeze_3_loss: 5.9799 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 11.3962 - tf.compat.v1.squeeze_loss: 5.6311 - tf.compat.v1.squeeze_1_loss: 5.7651 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10.3882 - tf.compat.v1.squeeze_2_loss: 5.5356 - tf.compat.v1.squeeze_3_loss: 4.8526 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10.2946 - tf.compat.v1.squeeze_loss: 5.1222 - tf.compat.v1.squeeze_1_loss: 5.1724 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10.7807 - tf.compat.v1.squeeze_2_loss: 5.2469 - tf.compat.v1.squeeze_3_loss: 5.5339 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10.8921 - tf.compat.v1.squeeze_loss: 5.6573 - tf.compat.v1.squeeze_1_loss: 5.2348 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.5116 - tf.compat.v1.squeeze_2_loss: 4.6207 - tf.compat.v1.squeeze_3_loss: 4.8909 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10.6143 - tf.compat.v1.squeeze_loss: 5.5359 - tf.compat.v1.squeeze_1_loss: 5.0784 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10.0886 - tf.compat.v1.squeeze_2_loss: 5.1825 - tf.compat.v1.squeeze_3_loss: 4.9060 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10.9061 - tf.compat.v1.squeeze_loss: 5.4682 - tf.compat.v1.squeeze_1_loss: 5.4379 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10.2422 - tf.compat.v1.squeeze_2_loss: 4.9182 - tf.compat.v1.squeeze_3_loss: 5.3240 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10.1808 - tf.compat.v1.squeeze_loss: 5.2821 - tf.compat.v1.squeeze_1_loss: 4.8987 - tf.compat.v1.squeeze_accuracy: 0.2500 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10.5376 - tf.compat.v1.squeeze_2_loss: 5.3479 - tf.compat.v1.squeeze_3_loss: 5.1896 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10.4844 - tf.compat.v1.squeeze_loss: 5.4043 - tf.compat.v1.squeeze_1_loss: 5.0802 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.6583 - tf.compat.v1.squeeze_2_loss: 4.7512 - tf.compat.v1.squeeze_3_loss: 4.9070 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.6989 - tf.compat.v1.squeeze_loss: 4.8989 - tf.compat.v1.squeeze_1_loss: 4.8000 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.8941 - tf.compat.v1.squeeze_2_loss: 4.4310 - tf.compat.v1.squeeze_3_loss: 5.4631 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.8695 - tf.compat.v1.squeeze_loss: 5.5125 - tf.compat.v1.squeeze_1_loss: 4.3570 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10.6221 - tf.compat.v1.squeeze_2_loss: 5.3712 - tf.compat.v1.squeeze_3_loss: 5.2510 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10.4773 - tf.compat.v1.squeeze_loss: 5.2620 - tf.compat.v1.squeeze_1_loss: 5.2153 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.6932 - tf.compat.v1.squeeze_2_loss: 4.5638 - tf.compat.v1.squeeze_3_loss: 5.1294 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10.2961 - tf.compat.v1.squeeze_loss: 5.0320 - tf.compat.v1.squeeze_1_loss: 5.2642 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10.2653 - tf.compat.v1.squeeze_2_loss: 4.8415 - tf.compat.v1.squeeze_3_loss: 5.4238 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10.8708 - tf.compat.v1.squeeze_loss: 5.1133 - tf.compat.v1.squeeze_1_loss: 5.7575 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10.9614 - tf.compat.v1.squeeze_2_loss: 5.1751 - tf.compat.v1.squeeze_3_loss: 5.7863 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10.1018 - tf.compat.v1.squeeze_loss: 4.7484 - tf.compat.v1.squeeze_1_loss: 5.3535 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 9.1811 - tf.compat.v1.squeeze_2_loss: 4.5606 - tf.compat.v1.squeeze_3_loss: 4.6205 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.8583 - tf.compat.v1.squeeze_loss: 4.2661 - tf.compat.v1.squeeze_1_loss: 4.5921 - tf.compat.v1.squeeze_accuracy: 0.2500 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.4498 - tf.compat.v1.squeeze_2_loss: 4.1531 - tf.compat.v1.squeeze_3_loss: 4.2967 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.6956 - tf.compat.v1.squeeze_loss: 5.0596 - tf.compat.v1.squeeze_1_loss: 4.6360 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10.4209 - tf.compat.v1.squeeze_2_loss: 5.1601 - tf.compat.v1.squeeze_3_loss: 5.2607 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10.4945 - tf.compat.v1.squeeze_loss: 5.5962 - tf.compat.v1.squeeze_1_loss: 4.8983 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 9.2698 - tf.compat.v1.squeeze_2_loss: 4.6748 - tf.compat.v1.squeeze_3_loss: 4.5950 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.9048 - tf.compat.v1.squeeze_loss: 5.3051 - tf.compat.v1.squeeze_1_loss: 4.5997 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.7707 - tf.compat.v1.squeeze_2_loss: 4.1310 - tf.compat.v1.squeeze_3_loss: 4.6397 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 7.8872 - tf.compat.v1.squeeze_loss: 4.5039 - tf.compat.v1.squeeze_1_loss: 3.3833 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.6950 - tf.compat.v1.squeeze_2_loss: 4.2927 - tf.compat.v1.squeeze_3_loss: 4.4022 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.7182 - tf.compat.v1.squeeze_loss: 4.8583 - tf.compat.v1.squeeze_1_loss: 3.8599 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.3289 - tf.compat.v1.squeeze_2_loss: 4.7996 - tf.compat.v1.squeeze_3_loss: 4.5293 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 9.0500 - tf.compat.v1.squeeze_loss: 4.3676 - tf.compat.v1.squeeze_1_loss: 4.6824 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 9.8318 - tf.compat.v1.squeeze_2_loss: 4.8018 - tf.compat.v1.squeeze_3_loss: 5.0300 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10.2966 - tf.compat.v1.squeeze_loss: 5.2360 - tf.compat.v1.squeeze_1_loss: 5.0606 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.3339 - tf.compat.v1.squeeze_2_loss: 4.4662 - tf.compat.v1.squeeze_3_loss: 3.8677 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 8.8902 - tf.compat.v1.squeeze_loss: 4.5322 - tf.compat.v1.squeeze_1_loss: 4.3580 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9.6013 - tf.compat.v1.squeeze_2_loss: 4.8256 - tf.compat.v1.squeeze_3_loss: 4.7757 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.6726 - tf.compat.v1.squeeze_loss: 5.3028 - tf.compat.v1.squeeze_1_loss: 4.3698 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 10.1965 - tf.compat.v1.squeeze_2_loss: 4.7395 - tf.compat.v1.squeeze_3_loss: 5.4570 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.9579 - tf.compat.v1.squeeze_loss: 5.0447 - tf.compat.v1.squeeze_1_loss: 4.9133 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 9.1020 - tf.compat.v1.squeeze_2_loss: 4.4458 - tf.compat.v1.squeeze_3_loss: 4.6562 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 8.9358 - tf.compat.v1.squeeze_loss: 4.7105 - tf.compat.v1.squeeze_1_loss: 4.2253 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 9.7868 - tf.compat.v1.squeeze_2_loss: 4.7443 - tf.compat.v1.squeeze_3_loss: 5.0425 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.8816 - tf.compat.v1.squeeze_loss: 4.8488 - tf.compat.v1.squeeze_1_loss: 4.0328 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 8.3962 - tf.compat.v1.squeeze_2_loss: 3.9454 - tf.compat.v1.squeeze_3_loss: 4.4508 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7648 - tf.compat.v1.squeeze_loss: 4.5478 - tf.compat.v1.squeeze_1_loss: 4.2170 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7858 - tf.compat.v1.squeeze_2_loss: 3.9110 - tf.compat.v1.squeeze_3_loss: 4.8748 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.7690 - tf.compat.v1.squeeze_loss: 4.5178 - tf.compat.v1.squeeze_1_loss: 4.2512 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.7115 - tf.compat.v1.squeeze_2_loss: 4.2411 - tf.compat.v1.squeeze_3_loss: 4.4704 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10.5165 - tf.compat.v1.squeeze_loss: 5.3578 - tf.compat.v1.squeeze_1_loss: 5.1587 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10.4504 - tf.compat.v1.squeeze_2_loss: 5.1922 - tf.compat.v1.squeeze_3_loss: 5.2583 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10.8825 - tf.compat.v1.squeeze_loss: 5.3474 - tf.compat.v1.squeeze_1_loss: 5.5351 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.0922 - tf.compat.v1.squeeze_2_loss: 3.9386 - tf.compat.v1.squeeze_3_loss: 4.1536 - tf.compat.v1.squeeze_2_accuracy: 0.2500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 8.7962 - tf.compat.v1.squeeze_loss: 4.3933 - tf.compat.v1.squeeze_1_loss: 4.4029 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 7.7862 - tf.compat.v1.squeeze_2_loss: 4.0312 - tf.compat.v1.squeeze_3_loss: 3.7550 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8.3022 - tf.compat.v1.squeeze_loss: 4.0789 - tf.compat.v1.squeeze_1_loss: 4.2233 - tf.compat.v1.squeeze_accuracy: 0.2500 - tf.compat.v1.squeeze_1_accuracy: 0.2500\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 9.3870 - tf.compat.v1.squeeze_2_loss: 4.7866 - tf.compat.v1.squeeze_3_loss: 4.6004 - tf.compat.v1.squeeze_2_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.0872 - tf.compat.v1.squeeze_loss: 4.6345 - tf.compat.v1.squeeze_1_loss: 4.4527 - tf.compat.v1.squeeze_accuracy: 0.0000e+00 - tf.compat.v1.squeeze_1_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.0912 - tf.compat.v1.squeeze_2_loss: 3.5136 - tf.compat.v1.squeeze_3_loss: 3.5776 - tf.compat.v1.squeeze_2_accuracy: 0.7500 - tf.compat.v1.squeeze_3_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nSameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;4bf2625991a584e8;/job:localhost/replica:0/task:0/device:GPU:0;edge_25_IteratorGetNext;0:0\n\t [[{{node IteratorGetNext/_6}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_37289]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m Y \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m model_current \u001b[39min\u001b[39;00m model_list:\n\u001b[1;32m     15\u001b[0m     \u001b[39m# Fit the generated dataset once\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     model_current\u001b[39m.\u001b[39;49mfit(X, Y, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m \u001b[39m# increment counter\u001b[39;00m\n\u001b[1;32m     19\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/python/py311/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/python/py311/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nSameWorkerRecvDone unable to allocate output tensor. Key: /job:localhost/replica:0/task:0/device:CPU:0;4bf2625991a584e8;/job:localhost/replica:0/task:0/device:GPU:0;edge_25_IteratorGetNext;0:0\n\t [[{{node IteratorGetNext/_6}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_37289]"
     ]
    }
   ],
   "source": [
    "import models.bert_embedding_parser as bert_embedding_parser\n",
    "\n",
    "gen = bert_embedding_parser.load_bert_embeddings(bert_model, batch_size=4)\n",
    "\n",
    "i = 0\n",
    "max_batches = 8248  # Can be any number; this is pre-calculated based on the amount of training data used; 8248 goes through entire dataset at batch size of 16\n",
    "\n",
    "\n",
    "for batch in gen:\n",
    "    # Read in the batch of data from generator\n",
    "    X = batch[0]\n",
    "    Y = batch[1]\n",
    "\n",
    "    for model_current in model_list:\n",
    "        # Fit the generated dataset once\n",
    "        model_current.fit(X, Y, epochs=1)\n",
    "\n",
    "    # increment counter\n",
    "    i += 1\n",
    "    del batch  # delete the batch to free up memory\n",
    "\n",
    "    # When the number of\n",
    "    if i == max_batches:  # 4 batches; can save each quarter\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "weights_dir = \"weights\"\n",
    "n = 0\n",
    "for m in model_list:\n",
    "    n += 1\n",
    "    m.save_weights(weights_dir + \"/%s.h5\" % m.name)\n",
    "\n",
    "\n",
    "# TODO: print out the 25 weights for each model (before and after fine-tuning)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
